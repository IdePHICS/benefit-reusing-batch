# The Benefits of Reusing Batch for Gradient Descent in Two-Layer Networks:
Breaking the Curse of Information and Leap Exponents
